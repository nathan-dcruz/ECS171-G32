{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Group 32\n",
    "## SVM Model - Cancer Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "564    1\n",
      "565    1\n",
      "566    1\n",
      "567    1\n",
      "568    0\n",
      "Name: diagnosis_B, Length: 569, dtype: int64\n",
      "(569, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>smoothness_se</th>\n",
       "      <th>compactness_se</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>diagnosis_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.990</td>\n",
       "      <td>10.38</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.570</td>\n",
       "      <td>17.77</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.690</td>\n",
       "      <td>21.25</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.420</td>\n",
       "      <td>20.38</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.290</td>\n",
       "      <td>14.34</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>20.260</td>\n",
       "      <td>23.03</td>\n",
       "      <td>0.09078</td>\n",
       "      <td>0.13130</td>\n",
       "      <td>0.2095</td>\n",
       "      <td>0.05649</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>1.5090</td>\n",
       "      <td>0.006016</td>\n",
       "      <td>0.03482</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>24.22</td>\n",
       "      <td>31.59</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>0.35390</td>\n",
       "      <td>0.3689</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>12.180</td>\n",
       "      <td>17.84</td>\n",
       "      <td>0.10450</td>\n",
       "      <td>0.07057</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.06635</td>\n",
       "      <td>0.3661</td>\n",
       "      <td>1.5110</td>\n",
       "      <td>0.005433</td>\n",
       "      <td>0.01179</td>\n",
       "      <td>0.02220</td>\n",
       "      <td>12.83</td>\n",
       "      <td>20.92</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.09358</td>\n",
       "      <td>0.2227</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>9.787</td>\n",
       "      <td>19.94</td>\n",
       "      <td>0.10240</td>\n",
       "      <td>0.05301</td>\n",
       "      <td>0.1350</td>\n",
       "      <td>0.06890</td>\n",
       "      <td>0.3350</td>\n",
       "      <td>2.0430</td>\n",
       "      <td>0.011130</td>\n",
       "      <td>0.01463</td>\n",
       "      <td>0.01801</td>\n",
       "      <td>10.92</td>\n",
       "      <td>26.29</td>\n",
       "      <td>0.1316</td>\n",
       "      <td>0.09473</td>\n",
       "      <td>0.1934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>11.600</td>\n",
       "      <td>12.84</td>\n",
       "      <td>0.08983</td>\n",
       "      <td>0.07525</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.06582</td>\n",
       "      <td>0.2315</td>\n",
       "      <td>0.5391</td>\n",
       "      <td>0.006153</td>\n",
       "      <td>0.01330</td>\n",
       "      <td>0.01651</td>\n",
       "      <td>13.06</td>\n",
       "      <td>17.16</td>\n",
       "      <td>0.1431</td>\n",
       "      <td>0.18510</td>\n",
       "      <td>0.2772</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>14.420</td>\n",
       "      <td>19.77</td>\n",
       "      <td>0.09752</td>\n",
       "      <td>0.11410</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>0.06390</td>\n",
       "      <td>0.2895</td>\n",
       "      <td>1.8510</td>\n",
       "      <td>0.008005</td>\n",
       "      <td>0.02895</td>\n",
       "      <td>0.01462</td>\n",
       "      <td>16.33</td>\n",
       "      <td>30.86</td>\n",
       "      <td>0.1431</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.2718</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    radius_mean  texture_mean  smoothness_mean  compactness_mean  \\\n",
       "0        17.990         10.38          0.11840           0.27760   \n",
       "1        20.570         17.77          0.08474           0.07864   \n",
       "2        19.690         21.25          0.10960           0.15990   \n",
       "3        11.420         20.38          0.14250           0.28390   \n",
       "4        20.290         14.34          0.10030           0.13280   \n",
       "..          ...           ...              ...               ...   \n",
       "95       20.260         23.03          0.09078           0.13130   \n",
       "96       12.180         17.84          0.10450           0.07057   \n",
       "97        9.787         19.94          0.10240           0.05301   \n",
       "98       11.600         12.84          0.08983           0.07525   \n",
       "99       14.420         19.77          0.09752           0.11410   \n",
       "\n",
       "    symmetry_mean  fractal_dimension_mean  radius_se  texture_se  \\\n",
       "0          0.2419                 0.07871     1.0950      0.9053   \n",
       "1          0.1812                 0.05667     0.5435      0.7339   \n",
       "2          0.2069                 0.05999     0.7456      0.7869   \n",
       "3          0.2597                 0.09744     0.4956      1.1560   \n",
       "4          0.1809                 0.05883     0.7572      0.7813   \n",
       "..            ...                     ...        ...         ...   \n",
       "95         0.2095                 0.05649     0.7576      1.5090   \n",
       "96         0.1900                 0.06635     0.3661      1.5110   \n",
       "97         0.1350                 0.06890     0.3350      2.0430   \n",
       "98         0.1620                 0.06582     0.2315      0.5391   \n",
       "99         0.1879                 0.06390     0.2895      1.8510   \n",
       "\n",
       "    smoothness_se  compactness_se  symmetry_se  radius_worst  texture_worst  \\\n",
       "0        0.006399         0.04904      0.03003         25.38          17.33   \n",
       "1        0.005225         0.01308      0.01389         24.99          23.41   \n",
       "2        0.006150         0.04006      0.02250         23.57          25.53   \n",
       "3        0.009110         0.07458      0.05963         14.91          26.50   \n",
       "4        0.011490         0.02461      0.01756         22.54          16.67   \n",
       "..            ...             ...          ...           ...            ...   \n",
       "95       0.006016         0.03482      0.02657         24.22          31.59   \n",
       "96       0.005433         0.01179      0.02220         12.83          20.92   \n",
       "97       0.011130         0.01463      0.01801         10.92          26.29   \n",
       "98       0.006153         0.01330      0.01651         13.06          17.16   \n",
       "99       0.008005         0.02895      0.01462         16.33          30.86   \n",
       "\n",
       "    smoothness_worst  compactness_worst  symmetry_worst  diagnosis_B  \n",
       "0             0.1622            0.66560          0.4601            1  \n",
       "1             0.1238            0.18660          0.2750            1  \n",
       "2             0.1444            0.42450          0.3613            1  \n",
       "3             0.2098            0.86630          0.6638            1  \n",
       "4             0.1374            0.20500          0.2364            1  \n",
       "..               ...                ...             ...          ...  \n",
       "95            0.1190            0.35390          0.3689            1  \n",
       "96            0.1140            0.09358          0.2227            0  \n",
       "97            0.1316            0.09473          0.1934            0  \n",
       "98            0.1431            0.18510          0.2772            0  \n",
       "99            0.1431            0.30260          0.2718            1  \n",
       "\n",
       "[100 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "KFOLD_SPLITS = 10 \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.naive_bayes import GaussianNB, CategoricalNB\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, make_scorer, confusion_matrix, classification_report, mean_squared_error, accuracy_score, precision_score, recall_score, r2_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from IPython.display import display # Just for solution\n",
    "\n",
    "drop_columns = ['id', \n",
    "                'perimeter_mean', 'area_mean', 'concavity_mean', 'concave points_mean',\n",
    "                'perimeter_se', 'area_se', 'concavity_se', 'concave points_se', 'fractal_dimension_se',\n",
    "                'perimeter_worst', 'area_worst', 'concavity_worst', 'concave points_worst', 'fractal_dimension_worst',\n",
    "                ]\n",
    "\n",
    "df = pd.read_csv('Cancer_Data.csv')\n",
    "df = df.drop(drop_columns, axis = 1)\n",
    "\n",
    "cats = [\"radius_mean\",\"texture_mean\", \"smoothness_mean\",\"compactness_mean\",\"symmetry_mean\",\"fractal_dimension_mean\",\"radius_se\",\"texture_se\",\"smoothness_se\", \"compactness_se\",\"symmetry_se\",\"radius_worst\",\"texture_worst\",\"smoothness_worst\",\"compactness_worst\",\"symmetry_worst\"]\n",
    "df['diagnosis_B'] = df['diagnosis'] == 'M'\n",
    "df['diagnosis_B'] = df['diagnosis_B'].replace({True: 1, False: 0})\n",
    "\n",
    "print(df['diagnosis_B'])\n",
    "df = df.drop(columns=['diagnosis'])\n",
    "\n",
    "print(df.shape)\n",
    "display(df.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for batch  0  :  0.9122807017543859\n",
      "Mean Square Error for batch  0  :  0.08771929824561403\n",
      "\n",
      "Accuracy for batch  1  :  0.9473684210526315\n",
      "Mean Square Error for batch  1  :  0.05263157894736842\n",
      "\n",
      "Accuracy for batch  2  :  0.9473684210526315\n",
      "Mean Square Error for batch  2  :  0.05263157894736842\n",
      "\n",
      "Accuracy for batch  3  :  0.9473684210526315\n",
      "Mean Square Error for batch  3  :  0.05263157894736842\n",
      "\n",
      "Accuracy for batch  4  :  0.9649122807017544\n",
      "Mean Square Error for batch  4  :  0.03508771929824561\n",
      "\n",
      "Accuracy for batch  5  :  0.9824561403508771\n",
      "Mean Square Error for batch  5  :  0.017543859649122806\n",
      "\n",
      "Accuracy for batch  6  :  0.9824561403508771\n",
      "Mean Square Error for batch  6  :  0.017543859649122806\n",
      "\n",
      "Accuracy for batch  7  :  0.9649122807017544\n",
      "Mean Square Error for batch  7  :  0.03508771929824561\n",
      "\n",
      "Accuracy for batch  8  :  0.9649122807017544\n",
      "Mean Square Error for batch  8  :  0.03508771929824561\n",
      "\n",
      "Accuracy for batch  9  :  0.9464285714285714\n",
      "Mean Square Error for batch  9  :  0.05357142857142857\n",
      "\n",
      "Average Accuracy =  0.9560463659147869\n",
      "Average MSE =  0.04395363408521303\n",
      "Confusion Matrix:\n",
      " [[11  0]\n",
      " [ 5 41]]\n",
      "TPR: 0.8913043478260869\n",
      "TNR: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.81        11\n",
      "           1       1.00      0.89      0.94        46\n",
      "\n",
      "    accuracy                           0.91        57\n",
      "   macro avg       0.84      0.95      0.88        57\n",
      "weighted avg       0.94      0.91      0.92        57\n",
      "\n",
      "AUC1 SCORE: 0.9960474308300395\n",
      "Confusion Matrix:\n",
      " [[35  0]\n",
      " [ 3 19]]\n",
      "TPR: 0.8636363636363636\n",
      "TNR: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        35\n",
      "           1       1.00      0.86      0.93        22\n",
      "\n",
      "    accuracy                           0.95        57\n",
      "   macro avg       0.96      0.93      0.94        57\n",
      "weighted avg       0.95      0.95      0.95        57\n",
      "\n",
      "AUC1 SCORE: 0.996103896103896\n",
      "Confusion Matrix:\n",
      " [[35  1]\n",
      " [ 2 19]]\n",
      "TPR: 0.9047619047619048\n",
      "TNR: 0.9722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        36\n",
      "           1       0.95      0.90      0.93        21\n",
      "\n",
      "    accuracy                           0.95        57\n",
      "   macro avg       0.95      0.94      0.94        57\n",
      "weighted avg       0.95      0.95      0.95        57\n",
      "\n",
      "AUC1 SCORE: 0.9933862433862434\n",
      "Confusion Matrix:\n",
      " [[29  0]\n",
      " [ 3 25]]\n",
      "TPR: 0.8928571428571429\n",
      "TNR: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        29\n",
      "           1       1.00      0.89      0.94        28\n",
      "\n",
      "    accuracy                           0.95        57\n",
      "   macro avg       0.95      0.95      0.95        57\n",
      "weighted avg       0.95      0.95      0.95        57\n",
      "\n",
      "AUC1 SCORE: 1.0\n",
      "Confusion Matrix:\n",
      " [[28  1]\n",
      " [ 1 27]]\n",
      "TPR: 0.9642857142857143\n",
      "TNR: 0.9655172413793104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        29\n",
      "           1       0.96      0.96      0.96        28\n",
      "\n",
      "    accuracy                           0.96        57\n",
      "   macro avg       0.96      0.96      0.96        57\n",
      "weighted avg       0.96      0.96      0.96        57\n",
      "\n",
      "AUC1 SCORE: 0.9963054187192119\n",
      "Confusion Matrix:\n",
      " [[45  0]\n",
      " [ 1 11]]\n",
      "TPR: 0.9166666666666666\n",
      "TNR: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        45\n",
      "           1       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.98        57\n",
      "   macro avg       0.99      0.96      0.97        57\n",
      "weighted avg       0.98      0.98      0.98        57\n",
      "\n",
      "AUC1 SCORE: 0.9759259259259259\n",
      "Confusion Matrix:\n",
      " [[41  0]\n",
      " [ 1 15]]\n",
      "TPR: 0.9375\n",
      "TNR: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        41\n",
      "           1       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.98        57\n",
      "   macro avg       0.99      0.97      0.98        57\n",
      "weighted avg       0.98      0.98      0.98        57\n",
      "\n",
      "AUC1 SCORE: 0.9984756097560975\n",
      "Confusion Matrix:\n",
      " [[42  2]\n",
      " [ 0 13]]\n",
      "TPR: 1.0\n",
      "TNR: 0.9545454545454546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        44\n",
      "           1       0.87      1.00      0.93        13\n",
      "\n",
      "    accuracy                           0.96        57\n",
      "   macro avg       0.93      0.98      0.95        57\n",
      "weighted avg       0.97      0.96      0.97        57\n",
      "\n",
      "AUC1 SCORE: 1.0\n",
      "Confusion Matrix:\n",
      " [[42  2]\n",
      " [ 0 13]]\n",
      "TPR: 1.0\n",
      "TNR: 0.9545454545454546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        44\n",
      "           1       0.87      1.00      0.93        13\n",
      "\n",
      "    accuracy                           0.96        57\n",
      "   macro avg       0.93      0.98      0.95        57\n",
      "weighted avg       0.97      0.96      0.97        57\n",
      "\n",
      "AUC1 SCORE: 0.9982517482517482\n",
      "Confusion Matrix:\n",
      " [[41  2]\n",
      " [ 1 12]]\n",
      "TPR: 0.9230769230769231\n",
      "TNR: 0.9534883720930233\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.86      0.92      0.89        13\n",
      "\n",
      "    accuracy                           0.95        56\n",
      "   macro avg       0.92      0.94      0.93        56\n",
      "weighted avg       0.95      0.95      0.95        56\n",
      "\n",
      "AUC1 SCORE: 0.9928443649373881\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df.drop(columns=['diagnosis_B'])\n",
    "y = df['diagnosis_B']\n",
    "\n",
    "kf = KFold(n_splits=KFOLD_SPLITS)\n",
    "models = []\n",
    "\n",
    "acc = 0\n",
    "mse = 0\n",
    "\n",
    "i = 0 #keep track of batch number\n",
    "# step 5: iterate k times with a different testing subset\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "    # step 2-3: use k-1/k^th partition for the training/testing model\n",
    "    start_train, stop_train = train_indices[0], train_indices[-1]+1\n",
    "    start_test, stop_test = test_indices[0], test_indices[-1]+1\n",
    "\n",
    "    X_train, X_test = X[start_train:stop_train], X[start_test:stop_test]\n",
    "    y_train, y_test = y[start_train:stop_train], y[start_test:stop_test] \n",
    "\n",
    "    # Do Log Reg\n",
    "    svc_li = SVC(kernel='linear', probability=True)\n",
    "    svc_li.fit(X_train, y_train)\n",
    "    y_pred = svc_li.predict(X_test)\n",
    "\n",
    "    y_prob = svc_li.predict_proba(X_test)\n",
    "    details = {}\n",
    "\n",
    "    # y_test, y_pred, y_prob\n",
    "    details[\"y_test\"] = y_test\n",
    "    details[\"y_pred\"] = y_pred \n",
    "    details[\"y_prob\"] = y_prob \n",
    "    models.append(details)\n",
    "    \n",
    "    this_acc = accuracy_score(y_test, y_pred)\n",
    "    this_mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    acc += this_acc\n",
    "    mse += this_mse\n",
    "\n",
    "    # step 4: record the evaluating scores\n",
    "    print(\"\\nAccuracy for batch \", i, \" : \", this_acc)\n",
    "    print(\"Mean Square Error for batch \", i, \" : \", this_mse)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "# step 6: find the average and select the batch with highest evaluation scores\n",
    "print('\\nAverage Accuracy = ', acc / KFOLD_SPLITS)\n",
    "print('Average MSE = ', mse / KFOLD_SPLITS)\n",
    "\n",
    "# Analyze models\n",
    "for model in models:\n",
    "    y_test = model[\"y_test\"]\n",
    "    y_pred = model[\"y_pred\"]\n",
    "    y_prob = model[\"y_prob\"]\n",
    "    \n",
    "    cmat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"Confusion Matrix:\\n {cmat}\")\n",
    "\n",
    "    # Confusion matrix whose i-th row and j-th column entry indicates the number of \n",
    "    # samples with true label being i-th class and predicted label being j-th class.\n",
    "\n",
    "    tp = cmat[1, 1]\n",
    "    tn = cmat[0, 0]\n",
    "    fp = cmat[0, 1]\n",
    "    fn = cmat[1, 0]\n",
    "\n",
    "    tpr = tp / (tp + fn) # RECALL/SENSITIVITY \n",
    "    print(f\"TPR: {tpr}\")\n",
    "\n",
    "    tnr = tn / (tn + fp) # SPECIFICITY\n",
    "    print(f\"TNR: {tnr}\") \n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    fpr1, tpr1, thresholds1 = roc_curve(y_test, y_prob[:, 1])\n",
    "    auc1 = roc_auc_score(y_test, y_prob[:, 1])\n",
    "\n",
    "    # separate these properly later\n",
    "    plt.plot(fpr1, tpr1)\n",
    "    print(f\"AUC1 SCORE: {auc1}\")\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.3 - SVM with Over-sampling (10 points)\n",
    " - For the column `satisfied` in our **training set**, please **print out** the frequency of each class. \n",
    " - Oversample the **training data**. \n",
    " - For the column `satisfied` in the oversampled data, **print out** the frequency of each class  again.\n",
    " - Re-build the 2 SVMs with the same setting you have in Exercise 3.2, but **use oversampled training data** instead.\n",
    "     - Do not forget to scale the data first. As always, the scaling method is up to you.\n",
    " - Report the **testing result** with `classification_report`.\n",
    "\n",
    "You can use ANY methods listed on [here](https://imbalanced-learn.org/stable/references/over_sampling.html#) such as RandomOverSampler or SMOTE. <br > \n",
    "You are definitely welcomed to build your own oversampler. <br >\n",
    "\n",
    "Note that you do not have to over-sample your testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    282\n",
      "True     173\n",
      "Name: diagnosis_N, dtype: int64\n",
      "True     282\n",
      "False    282\n",
      "Name: diagnosis_N, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_svm_train.value_counts())\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "X_os, y_os = ros.fit_resample(X_svm_train, y_svm_train)\n",
    "\n",
    "print(y_os.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class SVM:\n",
    "    def __init__(self,lr=.005,iters=1000,lambda_p=0.01):\n",
    "        self.lr=lr\n",
    "        self.iters=iters\n",
    "        self.lambda_p = lambda_p\n",
    "\n",
    "        self.weight = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        n_samples,n_feat = X.shape\n",
    "        \n",
    "        self.weight = np.zeros(n_feat)\n",
    "        self.bias = 0\n",
    "        \n",
    "        y_true = np.where(y <= 0, -1, 1) # same as -1 if y <= 0 else 1\n",
    "        \n",
    "        for _ in range(self.iters):\n",
    "            for idx, sample in enumerate(X):\n",
    "                y_pred = y_true[idx]*(np.dot(sample,self.weight)-self.bias)\n",
    "\n",
    "                if y_pred>=1:\n",
    "                    self.weight -= self.lr * (2 * self.lambda_p * self.weight)\n",
    "                else:\n",
    "                    self.weight -= self.lr * (2 * self.lambda_p * self.weight - np.dot(sample, y_true[idx]))\n",
    "                    self.bias -= self.lr * y_true[idx]\n",
    "        \n",
    "    def predict(self,X):\n",
    "        # do a forward pass\n",
    "        y = np.dot(X, self.weight) - self.bias\n",
    "        return y>=0 # if > 0, belongs to class 0, else class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.67      1.00      0.80        75\n",
      "        True       1.00      0.05      0.10        39\n",
      "\n",
      "    accuracy                           0.68       114\n",
      "   macro avg       0.83      0.53      0.45       114\n",
      "weighted avg       0.78      0.68      0.56       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVM()\n",
    "svm.fit(Z_svm_train, np.asarray(y_svm_train))\n",
    "\n",
    "print(classification_report(y_svm_test, svm.predict(Z_svm_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
