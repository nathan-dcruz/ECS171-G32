{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Feed-Forward Neural Network\n",
    "\n",
    "Also, one thing we may consider is divide the attributes into small sets to test which ones are best fit attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0      842302         M        17.99         10.38          122.80     1001.0   \n",
      "1      842517         M        20.57         17.77          132.90     1326.0   \n",
      "2    84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3    84348301         M        11.42         20.38           77.58      386.1   \n",
      "4    84358402         M        20.29         14.34          135.10     1297.0   \n",
      "..        ...       ...          ...           ...             ...        ...   \n",
      "564    926424         M        21.56         22.39          142.00     1479.0   \n",
      "565    926682         M        20.13         28.25          131.20     1261.0   \n",
      "566    926954         M        16.60         28.08          108.30      858.1   \n",
      "567    927241         M        20.60         29.33          140.10     1265.0   \n",
      "568     92751         B         7.76         24.54           47.92      181.0   \n",
      "\n",
      "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0            0.11840           0.27760         0.30010              0.14710   \n",
      "1            0.08474           0.07864         0.08690              0.07017   \n",
      "2            0.10960           0.15990         0.19740              0.12790   \n",
      "3            0.14250           0.28390         0.24140              0.10520   \n",
      "4            0.10030           0.13280         0.19800              0.10430   \n",
      "..               ...               ...             ...                  ...   \n",
      "564          0.11100           0.11590         0.24390              0.13890   \n",
      "565          0.09780           0.10340         0.14400              0.09791   \n",
      "566          0.08455           0.10230         0.09251              0.05302   \n",
      "567          0.11780           0.27700         0.35140              0.15200   \n",
      "568          0.05263           0.04362         0.00000              0.00000   \n",
      "\n",
      "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
      "0    ...        25.380          17.33           184.60      2019.0   \n",
      "1    ...        24.990          23.41           158.80      1956.0   \n",
      "2    ...        23.570          25.53           152.50      1709.0   \n",
      "3    ...        14.910          26.50            98.87       567.7   \n",
      "4    ...        22.540          16.67           152.20      1575.0   \n",
      "..   ...           ...            ...              ...         ...   \n",
      "564  ...        25.450          26.40           166.10      2027.0   \n",
      "565  ...        23.690          38.25           155.00      1731.0   \n",
      "566  ...        18.980          34.12           126.70      1124.0   \n",
      "567  ...        25.740          39.42           184.60      1821.0   \n",
      "568  ...         9.456          30.37            59.16       268.6   \n",
      "\n",
      "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0             0.16220            0.66560           0.7119   \n",
      "1             0.12380            0.18660           0.2416   \n",
      "2             0.14440            0.42450           0.4504   \n",
      "3             0.20980            0.86630           0.6869   \n",
      "4             0.13740            0.20500           0.4000   \n",
      "..                ...                ...              ...   \n",
      "564           0.14100            0.21130           0.4107   \n",
      "565           0.11660            0.19220           0.3215   \n",
      "566           0.11390            0.30940           0.3403   \n",
      "567           0.16500            0.86810           0.9387   \n",
      "568           0.08996            0.06444           0.0000   \n",
      "\n",
      "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0                  0.2654          0.4601                  0.11890  \n",
      "1                  0.1860          0.2750                  0.08902  \n",
      "2                  0.2430          0.3613                  0.08758  \n",
      "3                  0.2575          0.6638                  0.17300  \n",
      "4                  0.1625          0.2364                  0.07678  \n",
      "..                    ...             ...                      ...  \n",
      "564                0.2216          0.2060                  0.07115  \n",
      "565                0.1628          0.2572                  0.06637  \n",
      "566                0.1418          0.2218                  0.07820  \n",
      "567                0.2650          0.4087                  0.12400  \n",
      "568                0.0000          0.2871                  0.07039  \n",
      "\n",
      "[569 rows x 32 columns]\n",
      "Dataset :\n",
      "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0    842302         M        17.99         10.38          122.80     1001.0   \n",
      "1    842517         M        20.57         17.77          132.90     1326.0   \n",
      "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3  84348301         M        11.42         20.38           77.58      386.1   \n",
      "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
      "0  ...         25.38          17.33           184.60      2019.0   \n",
      "1  ...         24.99          23.41           158.80      1956.0   \n",
      "2  ...         23.57          25.53           152.50      1709.0   \n",
      "3  ...         14.91          26.50            98.87       567.7   \n",
      "4  ...         22.54          16.67           152.20      1575.0   \n",
      "\n",
      "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   symmetry_worst  fractal_dimension_worst  \n",
      "0          0.4601                  0.11890  \n",
      "1          0.2750                  0.08902  \n",
      "2          0.3613                  0.08758  \n",
      "3          0.6638                  0.17300  \n",
      "4          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "Diagnosis : \n",
      "['M' 'B']\n",
      "Dimensions of the dataset :  (569, 32)\n",
      "Features of the dataset :\n",
      "                  id diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
      "count   5.690000e+02       569   569.000000    569.000000      569.000000   \n",
      "unique           NaN         2          NaN           NaN             NaN   \n",
      "top              NaN         B          NaN           NaN             NaN   \n",
      "freq             NaN       357          NaN           NaN             NaN   \n",
      "mean    3.037183e+07       NaN    14.127292     19.289649       91.969033   \n",
      "std     1.250206e+08       NaN     3.524049      4.301036       24.298981   \n",
      "min     8.670000e+03       NaN     6.981000      9.710000       43.790000   \n",
      "25%     8.692180e+05       NaN    11.700000     16.170000       75.170000   \n",
      "50%     9.060240e+05       NaN    13.370000     18.840000       86.240000   \n",
      "75%     8.813129e+06       NaN    15.780000     21.800000      104.100000   \n",
      "max     9.113205e+08       NaN    28.110000     39.280000      188.500000   \n",
      "\n",
      "          area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
      "count    569.000000       569.000000        569.000000      569.000000   \n",
      "unique          NaN              NaN               NaN             NaN   \n",
      "top             NaN              NaN               NaN             NaN   \n",
      "freq            NaN              NaN               NaN             NaN   \n",
      "mean     654.889104         0.096360          0.104341        0.088799   \n",
      "std      351.914129         0.014064          0.052813        0.079720   \n",
      "min      143.500000         0.052630          0.019380        0.000000   \n",
      "25%      420.300000         0.086370          0.064920        0.029560   \n",
      "50%      551.100000         0.095870          0.092630        0.061540   \n",
      "75%      782.700000         0.105300          0.130400        0.130700   \n",
      "max     2501.000000         0.163400          0.345400        0.426800   \n",
      "\n",
      "        concave points_mean  ...  radius_worst  texture_worst  \\\n",
      "count            569.000000  ...    569.000000     569.000000   \n",
      "unique                  NaN  ...           NaN            NaN   \n",
      "top                     NaN  ...           NaN            NaN   \n",
      "freq                    NaN  ...           NaN            NaN   \n",
      "mean               0.048919  ...     16.269190      25.677223   \n",
      "std                0.038803  ...      4.833242       6.146258   \n",
      "min                0.000000  ...      7.930000      12.020000   \n",
      "25%                0.020310  ...     13.010000      21.080000   \n",
      "50%                0.033500  ...     14.970000      25.410000   \n",
      "75%                0.074000  ...     18.790000      29.720000   \n",
      "max                0.201200  ...     36.040000      49.540000   \n",
      "\n",
      "        perimeter_worst   area_worst  smoothness_worst  compactness_worst  \\\n",
      "count        569.000000   569.000000        569.000000         569.000000   \n",
      "unique              NaN          NaN               NaN                NaN   \n",
      "top                 NaN          NaN               NaN                NaN   \n",
      "freq                NaN          NaN               NaN                NaN   \n",
      "mean         107.261213   880.583128          0.132369           0.254265   \n",
      "std           33.602542   569.356993          0.022832           0.157336   \n",
      "min           50.410000   185.200000          0.071170           0.027290   \n",
      "25%           84.110000   515.300000          0.116600           0.147200   \n",
      "50%           97.660000   686.500000          0.131300           0.211900   \n",
      "75%          125.400000  1084.000000          0.146000           0.339100   \n",
      "max          251.200000  4254.000000          0.222600           1.058000   \n",
      "\n",
      "        concavity_worst  concave points_worst  symmetry_worst  \\\n",
      "count        569.000000            569.000000      569.000000   \n",
      "unique              NaN                   NaN             NaN   \n",
      "top                 NaN                   NaN             NaN   \n",
      "freq                NaN                   NaN             NaN   \n",
      "mean           0.272188              0.114606        0.290076   \n",
      "std            0.208624              0.065732        0.061867   \n",
      "min            0.000000              0.000000        0.156500   \n",
      "25%            0.114500              0.064930        0.250400   \n",
      "50%            0.226700              0.099930        0.282200   \n",
      "75%            0.382900              0.161400        0.317900   \n",
      "max            1.252000              0.291000        0.663800   \n",
      "\n",
      "        fractal_dimension_worst  \n",
      "count                569.000000  \n",
      "unique                      NaN  \n",
      "top                         NaN  \n",
      "freq                        NaN  \n",
      "mean                   0.083946  \n",
      "std                    0.018061  \n",
      "min                    0.055040  \n",
      "25%                    0.071460  \n",
      "50%                    0.080040  \n",
      "75%                    0.092080  \n",
      "max                    0.207500  \n",
      "\n",
      "[11 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = pd.read_csv(\"Cancer_Data.csv\")\n",
    "print(dataset)\n",
    "\n",
    "print(\"Dataset :\")\n",
    "print(dataset.head())\n",
    "print(\"Diagnosis : \")\n",
    "print(dataset['diagnosis'].unique())\n",
    "\n",
    "print(\"Dimensions of the dataset : \", dataset.shape)\n",
    "print(\"Features of the dataset :\")\n",
    "print(dataset.describe(include = 'all'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      M\n",
       "1      M\n",
       "2      M\n",
       "3      M\n",
       "4      M\n",
       "      ..\n",
       "564    M\n",
       "565    M\n",
       "566    M\n",
       "567    M\n",
       "568    B\n",
       "Name: diagnosis, Length: 569, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, batch_size=100, hidden_layer_sizes=(10, 2),\n",
       "              learning_rate_init=0.4, max_iter=600, random_state=42,\n",
       "              solver=&#x27;sgd&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, batch_size=100, hidden_layer_sizes=(10, 2),\n",
       "              learning_rate_init=0.4, max_iter=600, random_state=42,\n",
       "              solver=&#x27;sgd&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='logistic', batch_size=100, hidden_layer_sizes=(10, 2),\n",
       "              learning_rate_init=0.4, max_iter=600, random_state=42,\n",
       "              solver='sgd')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "drop_columns = ['diagnosis', 'id', \n",
    "                'perimeter_mean', 'area_mean', 'concavity_mean', 'concave points_mean',\n",
    "                'perimeter_se', 'area_se', 'concavity_se', 'concave points_se', 'fractal_dimension_se',\n",
    "                'perimeter_worst', 'area_worst', 'concavity_worst', 'concave points_worst', 'fractal_dimension_worst',\n",
    "                ]\n",
    "\n",
    "# Pre-process data \n",
    "X = dataset.drop(drop_columns, axis=1)\n",
    "y = dataset['diagnosis']\n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_rescaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(data = X_rescaled, columns = X.columns)\n",
    "\n",
    "\n",
    "# Binarize\n",
    "y = y.map({'B': 0, 'M': 1})\n",
    "\n",
    "# set_of_classes = y.value_counts().index.tolist()\n",
    "# set_of_classes= pd.DataFrame({'diagnosis': set_of_classes})\n",
    "# y = pd.get_dummies(y)\n",
    "\n",
    "# print(\"Pre-processed data :\")\n",
    "# print(X)\n",
    "\n",
    "# print(\"Pre-processed class :\")\n",
    "# print(y)\n",
    "\n",
    "# #splitting data into ratio 70:30\n",
    "# data_train, data_test, class_train, class_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Number of nodes in each hidden layer should be (10, 2)\n",
    "# Learning rate should be 0.4\n",
    "# Number of epochs should be 600\n",
    "mlp = MLPClassifier(solver = 'sgd', random_state = 42, activation = 'logistic', learning_rate_init = 0.4, batch_size = 100, hidden_layer_sizes = (10, 2), max_iter = 600)\n",
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = dataset['diagnosis']\n",
    "# y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp.fit(data_train, class_train)\n",
    "\n",
    "# pred = mlp.predict(data_test)\n",
    "# pred\n",
    "#prediction on the test data. species are represented using the hot-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# print(\"Accuracy : \", accuracy_score(class_test, pred))\n",
    "# print(\"Mean Square Error : \", mean_squared_error(class_test, pred))\n",
    "\n",
    "# print(pred[:5])\n",
    "# print(\"Confusion Matrix for each label : \")\n",
    "# print(multilabel_confusion_matrix(class_test, pred))\n",
    "\n",
    "# print(\"Classification Report : \")\n",
    "# print(classification_report(class_test, pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We use k-fold Cross Validation to validate the FFNN model\n",
    "\n",
    "https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation/#:~:text=The%20key%20configuration%20parameter%20for,evaluate%20models%20is%20k%3D10.\n",
    "\n",
    "They say k = 10 is the most popular\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "[0.98611111 0.61971831 0.95774648 0.97183099 0.98591549 0.97183099\n",
      " 0.98591549 0.95774648]\n",
      "MSE\n",
      "[0.01388889 0.38028169 0.04225352 0.02816901 0.01408451 0.02816901\n",
      " 0.01408451 0.04225352]\n"
     ]
    }
   ],
   "source": [
    "# Using sklearn function cross_validate()\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "CV = cross_validate(mlp, X, y, cv=8, scoring=['accuracy', 'neg_mean_squared_error'])\n",
    "print('Accuracy')\n",
    "print(CV['test_accuracy'])\n",
    "print('MSE')\n",
    "print(-1*CV['test_neg_mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy =  0.929601917057903\n",
      "Average MSE =  0.07039808294209701\n"
     ]
    }
   ],
   "source": [
    "print('Average Accuracy = ', sum(CV['test_accuracy']) / len(CV['test_accuracy']))\n",
    "print('Average MSE = ', sum(-1 * CV['test_neg_mean_squared_error']) / len(CV['test_neg_mean_squared_error']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for batch  1  :  0.19298245614035087\n",
      "Mean Square Error for batch  1  :  0.8070175438596491\n",
      "\n",
      "Accuracy for batch  2  :  0.9298245614035088\n",
      "Mean Square Error for batch  2  :  0.07017543859649122\n",
      "\n",
      "Accuracy for batch  3  :  0.9649122807017544\n",
      "Mean Square Error for batch  3  :  0.03508771929824561\n",
      "\n",
      "Accuracy for batch  4  :  0.9473684210526315\n",
      "Mean Square Error for batch  4  :  0.05263157894736842\n",
      "\n",
      "Accuracy for batch  5  :  0.9649122807017544\n",
      "Mean Square Error for batch  5  :  0.03508771929824561\n",
      "\n",
      "Accuracy for batch  6  :  0.9824561403508771\n",
      "Mean Square Error for batch  6  :  0.017543859649122806\n",
      "\n",
      "Accuracy for batch  7  :  0.9824561403508771\n",
      "Mean Square Error for batch  7  :  0.017543859649122806\n",
      "\n",
      "Accuracy for batch  8  :  1.0\n",
      "Mean Square Error for batch  8  :  0.0\n",
      "\n",
      "Accuracy for batch  9  :  1.0\n",
      "Mean Square Error for batch  9  :  0.0\n",
      "\n",
      "Accuracy for batch  10  :  0.9107142857142857\n",
      "Mean Square Error for batch  10  :  0.08928571428571429\n",
      "\n",
      "Average Accuracy =  0.8875626566416039\n",
      "Average MSE =  0.11243734335839597\n",
      "Confusion Matrix:\n",
      " [[11  0]\n",
      " [46  0]]\n",
      "TPR: 0.0\n",
      "TNR: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      1.00      0.32        11\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.19        57\n",
      "   macro avg       0.10      0.50      0.16        57\n",
      "weighted avg       0.04      0.19      0.06        57\n",
      "\n",
      "AUC1 SCORE: 0.9624505928853754\n",
      "Confusion Matrix:\n",
      " [[35  0]\n",
      " [ 4 18]]\n",
      "TPR: 0.8181818181818182\n",
      "TNR: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        35\n",
      "           1       1.00      0.82      0.90        22\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.95      0.91      0.92        57\n",
      "weighted avg       0.94      0.93      0.93        57\n",
      "\n",
      "AUC1 SCORE: 0.9935064935064934\n",
      "Confusion Matrix:\n",
      " [[36  0]\n",
      " [ 2 19]]\n",
      "TPR: 0.9047619047619048\n",
      "TNR: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        36\n",
      "           1       1.00      0.90      0.95        21\n",
      "\n",
      "    accuracy                           0.96        57\n",
      "   macro avg       0.97      0.95      0.96        57\n",
      "weighted avg       0.97      0.96      0.96        57\n",
      "\n",
      "AUC1 SCORE: 0.996031746031746\n",
      "Confusion Matrix:\n",
      " [[29  0]\n",
      " [ 3 25]]\n",
      "TPR: 0.8928571428571429\n",
      "TNR: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        29\n",
      "           1       1.00      0.89      0.94        28\n",
      "\n",
      "    accuracy                           0.95        57\n",
      "   macro avg       0.95      0.95      0.95        57\n",
      "weighted avg       0.95      0.95      0.95        57\n",
      "\n",
      "AUC1 SCORE: 1.0\n",
      "Confusion Matrix:\n",
      " [[29  0]\n",
      " [ 2 26]]\n",
      "TPR: 0.9285714285714286\n",
      "TNR: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        29\n",
      "           1       1.00      0.93      0.96        28\n",
      "\n",
      "    accuracy                           0.96        57\n",
      "   macro avg       0.97      0.96      0.96        57\n",
      "weighted avg       0.97      0.96      0.96        57\n",
      "\n",
      "AUC1 SCORE: 1.0\n",
      "Confusion Matrix:\n",
      " [[45  0]\n",
      " [ 1 11]]\n",
      "TPR: 0.9166666666666666\n",
      "TNR: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        45\n",
      "           1       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.98        57\n",
      "   macro avg       0.99      0.96      0.97        57\n",
      "weighted avg       0.98      0.98      0.98        57\n",
      "\n",
      "AUC1 SCORE: 0.9648148148148148\n",
      "Confusion Matrix:\n",
      " [[41  0]\n",
      " [ 1 15]]\n",
      "TPR: 0.9375\n",
      "TNR: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        41\n",
      "           1       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.98        57\n",
      "   macro avg       0.99      0.97      0.98        57\n",
      "weighted avg       0.98      0.98      0.98        57\n",
      "\n",
      "AUC1 SCORE: 0.9984756097560975\n",
      "Confusion Matrix:\n",
      " [[44  0]\n",
      " [ 0 13]]\n",
      "TPR: 1.0\n",
      "TNR: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        44\n",
      "           1       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        57\n",
      "   macro avg       1.00      1.00      1.00        57\n",
      "weighted avg       1.00      1.00      1.00        57\n",
      "\n",
      "AUC1 SCORE: 1.0\n",
      "Confusion Matrix:\n",
      " [[44  0]\n",
      " [ 0 13]]\n",
      "TPR: 1.0\n",
      "TNR: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        44\n",
      "           1       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        57\n",
      "   macro avg       1.00      1.00      1.00        57\n",
      "weighted avg       1.00      1.00      1.00        57\n",
      "\n",
      "AUC1 SCORE: 1.0\n",
      "Confusion Matrix:\n",
      " [[38  5]\n",
      " [ 0 13]]\n",
      "TPR: 1.0\n",
      "TNR: 0.8837209302325582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94        43\n",
      "           1       0.72      1.00      0.84        13\n",
      "\n",
      "    accuracy                           0.91        56\n",
      "   macro avg       0.86      0.94      0.89        56\n",
      "weighted avg       0.94      0.91      0.92        56\n",
      "\n",
      "AUC1 SCORE: 0.9892665474060822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alpha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Alpha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Alpha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To find list of accuracy and MSE values\n",
    "# Without using the sklearn function cross_validate()\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, make_scorer\n",
    "\n",
    "n_splits=10\n",
    "# step 1: randomize the dataset and create k equal size partitions\n",
    "kf = KFold(n_splits=n_splits)\n",
    "models = []\n",
    "\n",
    "acc = 0\n",
    "mse = 0\n",
    "\n",
    "i = 0 #keep track of batch number\n",
    "# step 5: iterate k times with a different testing subset\n",
    "for train_indices, test_indices in kf.split(X):\n",
    "\n",
    "    # step 2-3: use k-1/k^th partition for the training/testing model\n",
    "    start_train, stop_train = train_indices[0], train_indices[-1]+1\n",
    "    start_test, stop_test = test_indices[0], test_indices[-1]+1\n",
    "\n",
    "    X_train, X_test = X[start_train:stop_train], X[start_test:stop_test]\n",
    "    y_train, y_test = y[start_train:stop_train], y[start_test:stop_test]\n",
    "\n",
    "    # perform the training similar to Q1\n",
    "    #this was based on the requirements in Q1\n",
    "    mlp = MLPClassifier(solver = 'sgd', random_state = 42, activation = 'logistic', learning_rate_init = 0.4, batch_size = 100, hidden_layer_sizes = (10, 2), max_iter = 600)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    y_prob = mlp.predict_proba(X_test)\n",
    "\n",
    "    details = {}\n",
    "    # y_test, y_pred, y_prob\n",
    "    details[\"y_test\"] = y_test\n",
    "    details[\"y_pred\"] = y_pred \n",
    "    details[\"y_prob\"] = y_prob \n",
    "    models.append(details)\n",
    "\n",
    "    # step 4: record the evaluating scores\n",
    "    i+=1\n",
    "    acc += accuracy_score(y_test, y_pred)\n",
    "    mse += mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    print(\"\\nAccuracy for batch \", i, \" : \", accuracy_score(y_test, y_pred))\n",
    "    print(\"Mean Square Error for batch \", i, \" : \", mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# step 6: find the average and select the batch with highest evaluation scores\n",
    "print('\\nAverage Accuracy = ', acc / n_splits)\n",
    "print('Average MSE = ', mse / n_splits)\n",
    "\n",
    "# Analyze models\n",
    "for model in models:\n",
    "    y_test = model[\"y_test\"]\n",
    "    y_pred = model[\"y_pred\"]\n",
    "    y_prob = model[\"y_prob\"]\n",
    "    \n",
    "    cmat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"Confusion Matrix:\\n {cmat}\")\n",
    "\n",
    "    # Confusion matrix whose i-th row and j-th column entry indicates the number of \n",
    "    # samples with true label being i-th class and predicted label being j-th class.\n",
    "\n",
    "    tp = cmat[1, 1]\n",
    "    tn = cmat[0, 0]\n",
    "    fp = cmat[0, 1]\n",
    "    fn = cmat[1, 0]\n",
    "\n",
    "    tpr = tp / (tp + fn) # RECALL/SENSITIVITY \n",
    "    print(f\"TPR: {tpr}\")\n",
    "\n",
    "    tnr = tn / (tn + fp) # SPECIFICITY\n",
    "    #tnr = cmat[1][1] / (cmat[1][1] + cmat[0][1])\n",
    "    print(f\"TNR: {tnr}\") \n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    #fpr0, tpr0, thresholds0 = roc_curve(y_test, y_prob[:, 0])\n",
    "    #auc0 = roc_auc_score(y_test, y_prob[:, 0])\n",
    "\n",
    "    fpr1, tpr1, thresholds1 = roc_curve(y_test, y_prob[:, 1])\n",
    "    auc1 = roc_auc_score(y_test, y_prob[:, 1])\n",
    "\n",
    "    #plt.plot(fpr0, tpr0)\n",
    "    # separate these properly later\n",
    "    plt.plot(fpr1, tpr1)\n",
    "\n",
    "    #print(f\"AUC1 SCORE: {auc0}\")\n",
    "    print(f\"AUC1 SCORE: {auc1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "mlp = MLPClassifier(solver = 'sgd', random_state = 42, activation = 'logistic', learning_rate_init = 0.4, batch_size = 100, hidden_layer_sizes = (10, 2), max_iter = 600)\n",
    "mlp.fit(X, y)\n",
    "pickle.dump(mlp, open(\"NN-Model\", 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"NN-Model\", \"rb\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
